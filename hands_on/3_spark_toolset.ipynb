{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import max, desc, col, window, column, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.0/libexec/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/27 10:27:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[6]\") \\\n",
    "                    .appName('spark_toolset') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "staticDataFrame = spark.read.format(\"csv\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .load(\"../data/retail-data/by-day/*.csv\")\n",
    "\n",
    "staticDataFrame.createOrReplaceTempView(\"retail_data\")\n",
    "staticSchema = staticDataFrame.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(InvoiceNo,StringType,true),StructField(StockCode,StringType,true),StructField(Description,StringType,true),StructField(Quantity,IntegerType,true),StructField(InvoiceDate,StringType,true),StructField(UnitPrice,DoubleType,true),StructField(CustomerID,DoubleType,true),StructField(Country,StringType,true)))\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(staticSchema)\n",
    "staticDataFrame.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------------+\n",
      "|CustomerId|              window|TotalPrice_within_Window|\n",
      "+----------+--------------------+------------------------+\n",
      "|   14075.0|{2011-12-05 08:00...|      316.78000000000003|\n",
      "|   18180.0|{2011-12-05 08:00...|                  310.73|\n",
      "|   15358.0|{2011-12-05 08:00...|       830.0600000000003|\n",
      "|   15392.0|{2011-12-05 08:00...|      304.40999999999997|\n",
      "|   15290.0|{2011-12-05 08:00...|      263.02000000000004|\n",
      "+----------+--------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "staticDataFrame.selectExpr(\"CustomerId\", \"(UnitPrice*Quantity) as TotalPrice\", \"InvoiceDate\") \\\n",
    "                .groupBy(col(\"CustomerId\"), window(col(\"InvoiceDate\"), \"1 day\")) \\\n",
    "                .sum(\"TotalPrice\").withColumnRenamed(\"sum(TotalPrice)\", \"TotalPrice_within_Window\") \\\n",
    "                .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "streamingDataFrame = spark.readStream \\\n",
    "                        .schema(staticSchema) \\\n",
    "                        .option(\"maxFilesPerTrigger\", \"1\") \\\n",
    "                        .format(\"csv\") \\\n",
    "                        .option(\"header\", \"true\") \\\n",
    "                        .load(\"../data/retail-data/by-day/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamingDataFrame.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaseByCustomerPerHour = streamingDataFrame.selectExpr(\"CustomerId\", \"(UnitPrice * Quantity) as TotalPrice\", \"InvoiceDate\") \\\n",
    "                    .groupBy( col(\"CustomerId\"), window(col(\"InvoiceDate\"), \"1 day\")) \\\n",
    "                    .sum(\"TotalPrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/27 11:04:26 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/wk/_nxf_xjj16s2_tbn7hkxcln80000gr/T/temporary-de14dc07-868a-43fd-83ed-26141fec0baf. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/05/27 11:04:26 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x1118bdfa0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "purchaseByCustomerPerHour.writeStream \\\n",
    "                            .format(\"memory\") \\\n",
    "                            .queryName(\"customer_purchases\") \\\n",
    "                            .outputMode(\"complete\") \\\n",
    "                            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/27 11:04:29 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/wk/_nxf_xjj16s2_tbn7hkxcln80000gr/T/temporary-ee8c5ad1-fa66-4d28-a5b7-fbaaa6136c2c. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/05/27 11:04:29 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x1118bdb20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----------+--------------------+------------------+\n",
      "|CustomerId|              window|   sum(TotalPrice)|\n",
      "+----------+--------------------+------------------+\n",
      "|   12921.0|{2010-12-01 08:00...|             322.4|\n",
      "|   16583.0|{2010-12-01 08:00...|233.45000000000002|\n",
      "|   17897.0|{2010-12-01 08:00...|            140.39|\n",
      "|   12748.0|{2010-12-01 08:00...|              4.95|\n",
      "|   15350.0|{2010-12-01 08:00...|            115.65|\n",
      "|   17809.0|{2010-12-01 08:00...|              34.8|\n",
      "|   13747.0|{2010-12-01 08:00...|              79.6|\n",
      "|   16250.0|{2010-12-01 08:00...|            226.14|\n",
      "|   15983.0|{2010-12-01 08:00...|            440.89|\n",
      "|   17511.0|{2010-12-01 08:00...|           1825.74|\n",
      "|   14001.0|{2010-12-01 08:00...|            301.24|\n",
      "|   17460.0|{2010-12-01 08:00...|              19.9|\n",
      "|   18074.0|{2010-12-01 08:00...|             489.6|\n",
      "|   12868.0|{2010-12-01 08:00...|             203.3|\n",
      "|   15513.0|{2010-12-01 08:00...|             357.0|\n",
      "|   13705.0|{2010-12-01 08:00...|318.14000000000004|\n",
      "|   13694.0|{2010-12-01 08:00...|            842.12|\n",
      "|   13468.0|{2010-12-01 08:00...|360.05000000000007|\n",
      "|   13408.0|{2010-12-01 08:00...|1024.6800000000003|\n",
      "|   14594.0|{2010-12-01 08:00...|254.99999999999997|\n",
      "+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----------+--------------------+------------------+\n",
      "|CustomerId|              window|   sum(TotalPrice)|\n",
      "+----------+--------------------+------------------+\n",
      "|   17235.0|{2010-12-02 08:00...|             341.9|\n",
      "|   16583.0|{2010-12-01 08:00...|233.45000000000002|\n",
      "|   12748.0|{2010-12-01 08:00...|              4.95|\n",
      "|   17809.0|{2010-12-01 08:00...|              34.8|\n",
      "|   16250.0|{2010-12-01 08:00...|            226.14|\n",
      "|   16244.0|{2010-12-02 08:00...|1056.6299999999994|\n",
      "|   13117.0|{2010-12-02 08:00...|202.11999999999998|\n",
      "|   17460.0|{2010-12-01 08:00...|              19.9|\n",
      "|   12868.0|{2010-12-01 08:00...|             203.3|\n",
      "|   16752.0|{2010-12-02 08:00...|             207.5|\n",
      "|   13491.0|{2010-12-02 08:00...|              98.9|\n",
      "|      null|{2010-12-02 08:00...|431.84999999999985|\n",
      "|   16781.0|{2010-12-02 08:00...|311.24999999999994|\n",
      "|   14092.0|{2010-12-02 08:00...|              -5.9|\n",
      "|   14625.0|{2010-12-02 08:00...|            -37.65|\n",
      "|   13705.0|{2010-12-01 08:00...|318.14000000000004|\n",
      "|   13408.0|{2010-12-01 08:00...|1024.6800000000003|\n",
      "|   14594.0|{2010-12-01 08:00...|254.99999999999997|\n",
      "|   13090.0|{2010-12-01 08:00...|             160.6|\n",
      "|   15111.0|{2010-12-02 08:00...|288.49999999999994|\n",
      "+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----------+--------------------+------------------+\n",
      "|CustomerId|              window|   sum(TotalPrice)|\n",
      "+----------+--------------------+------------------+\n",
      "|   12748.0|{2010-12-01 08:00...|              4.95|\n",
      "|   16250.0|{2010-12-01 08:00...|            226.14|\n",
      "|   16244.0|{2010-12-02 08:00...|1056.6299999999994|\n",
      "|   17460.0|{2010-12-01 08:00...|              19.9|\n",
      "|   13491.0|{2010-12-02 08:00...|              98.9|\n",
      "|   14625.0|{2010-12-02 08:00...|            -37.65|\n",
      "|   14594.0|{2010-12-01 08:00...|254.99999999999997|\n",
      "|   12921.0|{2010-12-01 08:00...|             322.4|\n",
      "|   14901.0|{2010-12-02 08:00...|204.15000000000006|\n",
      "|   15922.0|{2010-12-02 08:00...|              -5.9|\n",
      "|   14865.0|{2010-12-02 08:00...|              37.2|\n",
      "|   14443.0|{2010-12-02 08:00...|            -15.57|\n",
      "|   17511.0|{2010-12-01 08:00...|           1825.74|\n",
      "|   14679.0|{2010-12-03 08:00...|             -2.55|\n",
      "|   18041.0|{2010-12-02 08:00...| 428.9399999999999|\n",
      "|   13468.0|{2010-12-01 08:00...|360.05000000000007|\n",
      "|   12471.0|{2010-12-02 08:00...|             -17.0|\n",
      "|   17235.0|{2010-12-02 08:00...|             341.9|\n",
      "|   17949.0|{2010-12-03 08:00...|            1314.0|\n",
      "|   14092.0|{2010-12-02 08:00...|              -5.9|\n",
      "+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----------+--------------------+------------------+\n",
      "|CustomerId|              window|   sum(TotalPrice)|\n",
      "+----------+--------------------+------------------+\n",
      "|   12748.0|{2010-12-01 08:00...|              4.95|\n",
      "|   16250.0|{2010-12-01 08:00...|            226.14|\n",
      "|   16244.0|{2010-12-02 08:00...|1056.6299999999994|\n",
      "|   17460.0|{2010-12-01 08:00...|              19.9|\n",
      "|   13491.0|{2010-12-02 08:00...|              98.9|\n",
      "|   16353.0|{2010-12-05 08:00...|             204.0|\n",
      "|   14625.0|{2010-12-02 08:00...|            -37.65|\n",
      "|   14594.0|{2010-12-01 08:00...|254.99999999999997|\n",
      "|   12921.0|{2010-12-01 08:00...|             322.4|\n",
      "|   14901.0|{2010-12-02 08:00...|204.15000000000006|\n",
      "|   15922.0|{2010-12-02 08:00...|              -5.9|\n",
      "|   14865.0|{2010-12-02 08:00...|              37.2|\n",
      "|   14800.0|{2010-12-05 08:00...| 555.8399999999999|\n",
      "|   14443.0|{2010-12-02 08:00...|            -15.57|\n",
      "|   15235.0|{2010-12-05 08:00...| 85.55000000000001|\n",
      "|   17511.0|{2010-12-01 08:00...|           1825.74|\n",
      "|   14679.0|{2010-12-03 08:00...|             -2.55|\n",
      "|   18041.0|{2010-12-02 08:00...| 428.9399999999999|\n",
      "|   13468.0|{2010-12-01 08:00...|360.05000000000007|\n",
      "|   12471.0|{2010-12-02 08:00...|             -17.0|\n",
      "+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchaseByCustomerPerHour.writeStream \\\n",
    "                            .format(\"console\") \\\n",
    "                            .queryName(\"customer_purchases_2\") \\\n",
    "                            .outputMode(\"complete\") \\\n",
    "                            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in spark.streams.active:\n",
    "    query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: customer_purchases_2; line 1 pos 14;\n'Sort ['sum(TotalPrice) DESC NULLS LAST], true\n+- 'Project [*]\n   +- 'UnresolvedRelation [customer_purchases_2], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Vivek_Goyal/dev/core-codecommit/repos/ds/Spark-The-Definitive-Guide/hands_on/3_spark_toolset.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Vivek_Goyal/dev/core-codecommit/repos/ds/Spark-The-Definitive-Guide/hands_on/3_spark_toolset.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m spark\u001b[39m.\u001b[39;49msql(\u001b[39m\"\u001b[39;49m\u001b[39mSELECT * FROM customer_purchases_2 ORDER BY `sum(TotalPrice)` DESC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mshow(\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msql\u001b[39m(\u001b[39mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m     \u001b[39m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[39m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[39m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsparkSession\u001b[39m.\u001b[39;49msql(sqlQuery), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: customer_purchases_2; line 1 pos 14;\n'Sort ['sum(TotalPrice) DESC NULLS LAST], true\n+- 'Project [*]\n   +- 'UnresolvedRelation [customer_purchases_2], [], false\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM customer_purchases_2 ORDER BY `sum(TotalPrice)` DESC\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+\n",
      "|CustomerId|              window|   sum(TotalPrice)|\n",
      "+----------+--------------------+------------------+\n",
      "|   18102.0|{2010-12-07 08:00...|          25920.37|\n",
      "|      null|{2010-12-06 08:00...|23395.099999999904|\n",
      "|      null|{2010-12-03 08:00...| 23021.99999999999|\n",
      "|      null|{2010-12-09 08:00...|15354.279999999955|\n",
      "|      null|{2010-12-01 08:00...|12584.299999999988|\n",
      "+----------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM customer_purchases ORDER BY `sum(TotalPrice)` DESC\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staticDataFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "withColumn() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Vivek_Goyal/dev/core-codecommit/repos/ds/Spark-The-Definitive-Guide/hands_on/3_spark_toolset.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Vivek_Goyal/dev/core-codecommit/repos/ds/Spark-The-Definitive-Guide/hands_on/3_spark_toolset.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preppedDataFrame \u001b[39m=\u001b[39m staticDataFrame \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Vivek_Goyal/dev/core-codecommit/repos/ds/Spark-The-Definitive-Guide/hands_on/3_spark_toolset.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                     \u001b[39m.\u001b[39;49mna\u001b[39m.\u001b[39;49mfill(\u001b[39m0\u001b[39;49m) \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Vivek_Goyal/dev/core-codecommit/repos/ds/Spark-The-Definitive-Guide/hands_on/3_spark_toolset.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     \u001b[39m.\u001b[39;49mwithColumn(\u001b[39m\"\u001b[39;49m\u001b[39mday_of_week\u001b[39;49m\u001b[39m\"\u001b[39;49m, col(\u001b[39m\"\u001b[39;49m\u001b[39mInvoiceDate\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mEEEE\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Vivek_Goyal/dev/core-codecommit/repos/ds/Spark-The-Definitive-Guide/hands_on/3_spark_toolset.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     \u001b[39m.\u001b[39mcoalesce(\u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: withColumn() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "preppedDataFrame = staticDataFrame \\\n",
    "                    .na.fill(0) \\\n",
    "                    .withColumn(\"day_of_week\", date_format(col(\"InvoiceDate\"), \"EEEE\")) \\\n",
    "                    .coalesce(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
